{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"D:/Data/spam/spam.csv\", encoding= \"latin1\") # Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data[[\"v1\", \"v2\"]] #Getting necessary coloumns\n",
    "data.columns= [\"Target\", \"Text\"] # Renaming columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # Importing stopwords\n",
    "stop= stopwords.words(\"english\") #assigning stopwords to 'stop' variable\n",
    "data[\"Text\"]= data[\"Text\"].apply(lambda x: \" \".join(x.lower() for x in x.split() if x not in stop)) # lowercasing and removing stopwords\n",
    "data[\"Text\"]= data[\"Text\"].str.replace(\"[^\\w\\s]\", \" \") # removing all of the punctuation marks\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data[\"Text\"]= data[\"Text\"].apply(lambda x: \" \".join(lemmatizer.lemmatize(x) for x in x.split())) # Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i think go usf life around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  spam\n",
       "0  go jurong point crazy available bugis n great ...     0\n",
       "1                            ok lar joking wif u oni     0\n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...     1\n",
       "3                u dun say early hor u c already say     0\n",
       "4              nah i think go usf life around though     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import get_dummies \n",
    "dummies= get_dummies(data[\"Target\"], drop_first=\"True\") # Converting text to features of target variable and dropping the first column\n",
    "data= pd.concat([data ,dummies], axis= 1) # concatenating with the main dataframe\n",
    "data= data.drop(\"Target\", axis= 1) # Dropping the target vatiable because it is not required\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"spam\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the imbalanced data\n",
    "Upsampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maj= data[data[\"spam\"]==0]\n",
    "df_min= data[data[\"spam\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_unsampled= resample(df_min, replace= True, n_samples= 4825, random_state= 123)\n",
    "df= pd.concat([df_minority_unsampled, df_maj])\n",
    "df= df.sample(frac= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text to Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= Tokenizer(num_words= 20000)\n",
    "tokenizer.fit_on_texts(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq= tokenizer.texts_to_sequences(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pad_sequences(seq, maxlen= 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df[\"spam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Embedding\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D, BatchNormalization, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential([Embedding(20000, 100, input_length= 600),\n",
    "                  Dropout(0.5),\n",
    "                  Conv1D(128, 5, activation= 'relu'),\n",
    "                  MaxPooling1D(5),\n",
    "                  Dropout(0.5),\n",
    "                  BatchNormalization(),\n",
    "                  Conv1D(128, 5, activation= 'relu'),\n",
    "                  MaxPooling1D(5),\n",
    "                  Dropout(0.5),\n",
    "                  BatchNormalization(),\n",
    "                  Flatten(),\n",
    "                  Dense(128, activation= 'relu'),\n",
    "                  Dense(2, activation= 'softmax')\n",
    "                  ])\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df[\"spam\"]\n",
    "from keras.utils import to_categorical\n",
    "y= to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2) # train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7720 samples, validate on 1930 samples\n",
      "Epoch 1/5\n",
      "7720/7720 [==============================] - 76s 10ms/sample - loss: 0.2927 - acc: 0.8883 - val_loss: 1.3909 - val_acc: 0.5057\n",
      "Epoch 2/5\n",
      "7720/7720 [==============================] - 71s 9ms/sample - loss: 0.0541 - acc: 0.9858 - val_loss: 0.7783 - val_acc: 0.5098\n",
      "Epoch 3/5\n",
      "7720/7720 [==============================] - 71s 9ms/sample - loss: 0.0331 - acc: 0.9933 - val_loss: 0.0687 - val_acc: 0.9808\n",
      "Epoch 4/5\n",
      "7720/7720 [==============================] - 68s 9ms/sample - loss: 0.0327 - acc: 0.9943 - val_loss: 0.0373 - val_acc: 0.9922\n",
      "Epoch 5/5\n",
      "7720/7720 [==============================] - 67s 9ms/sample - loss: 0.0232 - acc: 0.9959 - val_loss: 0.0557 - val_acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x282dd328408>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs= 5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
